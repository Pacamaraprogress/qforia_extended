import streamlit as st
import google.generativeai as genai
import pandas as pd
import json
import re

# Custom CSS for better visibility and styling
def load_custom_css():
    st.markdown("""
    <style>
    /* Main app styling */
    .main {
        padding-top: 2rem;
    }
    
    /* Header styling */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    .main-header h1 {
        color: white !important;
        text-align: center;
        font-size: 2.5rem !important;
        margin-bottom: 0.5rem !important;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .main-header p {
        color: #f0f0f0 !important;
        text-align: center;
        font-size: 1.2rem;
        margin: 0 !important;
    }
    
    /* Sidebar styling */
    .css-1d391kg {
        background-color: #f8f9fa;
    }
    
    .sidebar-header {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        padding: 1rem;
        border-radius: 8px;
        margin-bottom: 1rem;
    }
    
    .sidebar-header h2 {
        color: white !important;
        margin: 0 !important;
        text-align: center;
    }
    
    /* Button styling */
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.75rem 1.5rem;
        font-weight: bold;
        font-size: 1.1rem;
        transition: all 0.3s ease;
        box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        width: 100%;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.3);
    }
    
    /* Input field styling */
    .stTextInput > div > div > input,
    .stTextArea > div > div > textarea {
        border: 2px solid #e1e5e9;
        border-radius: 8px;
        padding: 0.75rem;
        font-size: 1rem;
        transition: border-color 0.3s ease;
    }
    
    .stTextInput > div > div > input:focus,
    .stTextArea > div > div > textarea:focus {
        border-color: #667eea;
        box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
    }
    
    /* Radio button styling */
    .stRadio > div {
        background-color: white;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #e1e5e9;
    }
    
    /* Success/Error message styling */
    .stSuccess {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 8px;
        padding: 1rem;
    }
    
    .stError {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 8px;
        padding: 1rem;
    }
    
    .stWarning {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 8px;
        padding: 1rem;
    }
    
    /* DataFrame styling */
    .stDataFrame {
        border: 1px solid #e1e5e9;
        border-radius: 8px;
        overflow: hidden;
    }
    
    /* Info boxes */
    .info-box {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        color: white;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    .info-box h3 {
        margin-top: 0 !important;
        color: white !important;
    }
    
    /* Generation details box */
    .generation-details {
        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 5px solid #667eea;
    }
    
    /* Download button */
    .stDownloadButton > button {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        color: white;
        border: none;
        border-radius: 8px;
        padding: 0.75rem 1.5rem;
        font-weight: bold;
        transition: all 0.3s ease;
    }
    
    .stDownloadButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    /* Spinner styling */
    .stSpinner {
        text-align: center;
    }
    
    /* Hide Streamlit menu and footer */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* Custom spacing */
    .block-container {
        padding-top: 1rem;
        padding-bottom: 1rem;
    }
    </style>
    """, unsafe_allow_html=True)

# App config
st.set_page_config(
    page_title="Qforia - AI Query Fan-Out Simulator", 
    layout="wide",
    initial_sidebar_state="expanded",
    page_icon="üîç"
)

# Load custom CSS
load_custom_css()

# Main header with custom styling
st.markdown("""
<div class="main-header">
    <h1>üîç Qforia</h1>
    <p>Advanced Query Fan-Out Simulator for AI Search Surfaces</p>
</div>
""", unsafe_allow_html=True)

# Sidebar with enhanced styling
st.sidebar.markdown("""
<div class="sidebar-header">
    <h2>‚öôÔ∏è Configuration</h2>
</div>
""", unsafe_allow_html=True)

# API key input with better styling
gemini_key = st.sidebar.text_input(
    "üîë Gemini API Key", 
    type="password",
    help="Enter your Google Gemini API key to enable AI query generation"
)

# Query input with enhanced styling
user_query = st.sidebar.text_area(
    "üí≠ Enter your query", 
    "What's the best electric SUV for driving up mt rainier?", 
    height=120,
    help="Enter the query you want to expand and analyze"
)

# Mode selection with better styling
mode = st.sidebar.radio(
    "üéØ Search Mode", 
    ["AI Overview (simple)", "AI Mode (complex)"],
    help="Choose the complexity level for query generation"
)

# Add some information about the modes
st.sidebar.markdown("""
<div style="background-color: #f0f2f6; padding: 1rem; border-radius: 8px; margin-top: 1rem;">
    <h4 style="margin-top: 0;">Mode Information:</h4>
    <p><strong>AI Overview:</strong> Generates 10+ focused queries for quick insights</p>
    <p><strong>AI Mode:</strong> Generates 20+ comprehensive queries for deep analysis</p>
</div>
""", unsafe_allow_html=True)

# Configure Gemini
if gemini_key:
    genai.configure(api_key=gemini_key)
    model = genai.GenerativeModel("gemini-1.5-flash-latest")
else:
    st.error("üîê Please enter your Gemini API Key to proceed.")
    st.info("üí° You can get your API key from the Google AI Studio: https://makersuite.google.com/app/apikey")
    st.stop()

# Prompt with detailed Chain-of-Thought logic
def QUERY_FANOUT_PROMPT(q, mode):
    min_queries_simple = 10
    min_queries_complex = 20

    if mode == "AI Overview (simple)":
        num_queries_instruction = (
            f"First, analyze the user's query: \"{q}\". Based on its complexity and the '{mode}' mode, "
            f"**you must decide on an optimal number of queries to generate.** "
            f"This number must be **at least {min_queries_simple}**. "
            f"For a straightforward query, generating around {min_queries_simple}-{min_queries_simple + 2} queries might be sufficient. "
            f"If the query has a few distinct aspects or common follow-up questions, aim for a slightly higher number, perhaps {min_queries_simple + 3}-{min_queries_simple + 5} queries. "
            f"Provide a brief reasoning for why you chose this specific number of queries. The queries themselves should be tightly scoped and highly relevant."
        )
    else:  # AI Mode (complex)
        num_queries_instruction = (
            f"First, analyze the user's query: \"{q}\". Based on its complexity and the '{mode}' mode, "
            f"**you must decide on an optimal number of queries to generate.** "
            f"This number must be **at least {min_queries_complex}**. "
            f"For multifaceted queries requiring exploration of various angles, sub-topics, comparisons, or deeper implications, "
            f"you should generate a more comprehensive set, potentially {min_queries_complex + 5}-{min_queries_complex + 10} queries, or even more if the query is exceptionally broad or deep. "
            f"Provide a brief reasoning for why you chose this specific number of queries. The queries should be diverse and in-depth."
        )

    return (
        f"You are simulating Google's AI Mode query fan-out process for generative search systems.\n"
        f"The user's original query is: \"{q}\". The selected mode is: \"{mode}\".\n\n"
        f"**Your first task is to determine the total number of queries to generate and the reasoning for this number, based on the instructions below:**\n"
        f"{num_queries_instruction}\n\n"
        f"**Once you have decided on the number and the reasoning, generate exactly that many unique synthetic queries.**\n"
        "Each of the following query transformation types MUST be represented at least once in the generated set, if the total number of queries you decide to generate allows for it (e.g., if you generate 12 queries, try to include all 6 types at least once, and then add more of the relevant types):\n"
        "1. Reformulations\n2. Related Queries\n3. Implicit Queries\n4. Comparative Queries\n5. Entity Expansions\n6. Personalized Queries\n\n"
        "The 'reasoning' field for each *individual query* should explain why that specific query was generated in relation to the original query, its type, and the overall user intent.\n"
        "Do NOT include queries dependent on real-time user history or geolocation.\n\n"
        "Return only a valid JSON object. The JSON object should strictly follow this format:\n"
        "{\n"
        "  \"generation_details\": {\n"
        "    \"target_query_count\": 12, // This is an EXAMPLE number; you will DETERMINE the actual number based on your analysis.\n"
        "    \"reasoning_for_count\": \"The user query was moderately complex, so I chose to generate slightly more than the minimum for a simple overview to cover key aspects like X, Y, and Z.\" // This is an EXAMPLE reasoning; provide your own.\n"
        "  },\n"
        "  \"expanded_queries\": [\n"
        "    // Array of query objects. The length of this array MUST match your 'target_query_count'.\n"
        "    {\n"
        "      \"query\": \"Example query 1...\",\n"
        "      \"type\": \"reformulation\",\n"
        "      \"user_intent\": \"Example intent...\",\n"
        "      \"reasoning\": \"Example reasoning for this specific query...\"\n"
        "    },\n"
        "    // ... more query objects ...\n"
        "  ]\n"
        "}"
    )

# Fan-out generation function
def generate_fanout(query, mode):
    prompt = QUERY_FANOUT_PROMPT(query, mode)
    try:
        response = model.generate_content(prompt)
        json_text = response.text.strip()
        
        # Clean potential markdown code block fences
        if json_text.startswith("```json"):
            json_text = json_text[7:]
        if json_text.endswith("```"):
            json_text = json_text[:-3]
        json_text = json_text.strip()

        data = json.loads(json_text)
        generation_details = data.get("generation_details", {})
        expanded_queries = data.get("expanded_queries", [])

        # Store details for display
        st.session_state.generation_details = generation_details

        return expanded_queries
    except json.JSONDecodeError as e:
        st.error(f"üî¥ Failed to parse Gemini response as JSON: {e}")
        with st.expander("üîç View Raw Response"):
            st.text(json_text if 'json_text' in locals() else "N/A (error before json_text assignment)")
        st.session_state.generation_details = None
        return None
    except Exception as e:
        st.error(f"üî¥ An unexpected error occurred during generation: {e}")
        if hasattr(response, 'text'):
            with st.expander("üîç View Raw Response"):
                st.text(response.text)
        st.session_state.generation_details = None
        return None

# Initialize session state for generation_details if not present
if 'generation_details' not in st.session_state:
    st.session_state.generation_details = None

# Generate and display results
if st.sidebar.button("üöÄ Run Fan-Out Analysis"):
    # Clear previous details
    st.session_state.generation_details = None
    
    if not user_query.strip():
        st.warning("‚ö†Ô∏è Please enter a query to analyze.")
    else:
        with st.spinner("ü§ñ Generating query fan-out using Gemini AI... This may take a moment..."):
            results = generate_fanout(user_query, mode)

        if results:  # Check if results is not None and not empty
            st.success("‚úÖ Query fan-out analysis complete!")

            # Display the reasoning for the count if available
            if st.session_state.generation_details:
                details = st.session_state.generation_details
                generated_count = len(results)
                target_count_model = details.get('target_query_count', 'N/A')
                reasoning_model = details.get('reasoning_for_count', 'Not provided by model.')

                st.markdown("---")
                st.markdown("""
                <div class="generation-details">
                    <h3>üß† AI Model's Query Generation Strategy</h3>
                </div>
                """, unsafe_allow_html=True)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üéØ Target Queries", target_count_model)
                with col2:
                    st.metric("‚úÖ Generated Queries", generated_count)
                with col3:
                    match_status = "‚úÖ Perfect" if target_count_model == generated_count else "‚ö†Ô∏è Variance"
                    st.metric("üìä Match Status", match_status)
                
                st.markdown(f"**ü§î Model's Reasoning:** _{reasoning_model}_")
                
                if isinstance(target_count_model, int) and target_count_model != generated_count:
                    st.warning(f"‚ö†Ô∏è Note: Model aimed to generate {target_count_model} queries but actually produced {generated_count}.")
                
                st.markdown("---")
            else:
                st.info("‚ÑπÔ∏è Generation details (target count, reasoning) were not available from the model's response.")

            # Display results in a more visually appealing way
            st.subheader("üìä Generated Query Analysis")
            
            # Create tabs for different views
            tab1, tab2, tab3 = st.tabs(["üìã All Queries", "üìà Query Types", "üíæ Export Data"])
            
            with tab1:
                df = pd.DataFrame(results)
                st.dataframe(
                    df, 
                    use_container_width=True, 
                    height=(min(len(df), 20) + 1) * 35 + 3,
                    column_config={
                        "query": st.column_config.TextColumn("Query", width="large"),
                        "type": st.column_config.TextColumn("Type", width="small"),
                        "user_intent": st.column_config.TextColumn("Intent", width="medium"),
                        "reasoning": st.column_config.TextColumn("Reasoning", width="large")
                    }
                )
            
            with tab2:
                # Query type analysis
                type_counts = df['type'].value_counts()
                st.bar_chart(type_counts)
                
                # Show breakdown by type
                for query_type in type_counts.index:
                    with st.expander(f"üìù {query_type.title()} Queries ({type_counts[query_type]})"):
                        type_queries = df[df['type'] == query_type]
                        for _, row in type_queries.iterrows():
                            st.write(f"**Query:** {row['query']}")
                            st.write(f"**Intent:** {row['user_intent']}")
                            st.write(f"**Reasoning:** {row['reasoning']}")
                            st.write("---")
            
            with tab3:
                csv = df.to_csv(index=False).encode("utf-8")
                st.download_button(
                    "üì• Download Complete Analysis (CSV)", 
                    data=csv, 
                    file_name=f"qforia_analysis_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv", 
                    mime="text/csv"
                )
                
                # JSON export option
                json_data = json.dumps(results, indent=2).encode("utf-8")
                st.download_button(
                    "üì• Download Raw Data (JSON)", 
                    data=json_data, 
                    file_name=f"qforia_raw_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json", 
                    mime="application/json"
                )
        
        elif results is None:  # Error occurred in generate_fanout
            # Error message is already displayed by generate_fanout
            pass
        else:  # Handle empty results list (empty list, not None)
            st.warning("‚ö†Ô∏è No queries were generated. The model returned an empty list, or there was an issue.")

# Add footer with app information
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 2rem;">
    <p>üîç <strong>Qforia</strong> - Advanced Query Fan-Out Simulator</p>
    <p>Powered by Google Gemini AI | Built with Streamlit</p>
</div>
""", unsafe_allow_html=True)

